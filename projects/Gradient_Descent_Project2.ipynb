{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, the data set can be found in the following directory:\n",
    "Training Data : Datasets/gd_project2_train.csv\n",
    "Testing Data : Datasets/gd_project2_test.csv\n",
    "\n",
    "### Information about the dataset\n",
    "The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP) of the plant. A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is colected from and has effect on the Steam Turbine, he other three of the ambient variables effect the GT performance. For comparability with our baseline studies, and to allow 5x2 fold statistical tests be carried out, we provide the data shuffled five times. For each shuffling 2-fold CV is carried out and the resulting 10 measurements are used for statistical testing.\n",
    "Attribute Information:\n",
    "Features consist of hourly average ambient variables\n",
    "Temperature (T) in the range 1.81°C and 37.11°C,\n",
    "Ambient Pressure (AP) in the range 992.89-1033.30 milibar,\n",
    "Relative Humidity (RH) in the range 25.56% to 100.16%\n",
    "Exhaust Vacuum (V) in the range 25.36-81.56 cm Hg\n",
    "Net hourly electrical energy output (EP) 420.26-495.76 MW The averages are taken from various sensors located around the plant that record the ambient variables every second. The variables are given without normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "data_input=np.loadtxt('Datasets/gd_project2_train.csv',delimiter=',')\n",
    "data_test=np.loadtxt('Datasets/gd_project2_test.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    8.58,    38.38,  1021.03,    84.37,   482.26],\n",
       "       [   21.79,    58.2 ,  1017.21,    66.74,   446.94],\n",
       "       [   16.64,    48.92,  1011.55,    78.76,   452.56],\n",
       "       ..., \n",
       "       [   29.8 ,    69.34,  1009.36,    64.74,   437.65],\n",
       "       [   16.37,    54.3 ,  1017.94,    63.63,   459.97],\n",
       "       [   30.11,    62.04,  1010.69,    47.96,   444.42]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   11.95,    42.03,  1017.58,    90.89],\n",
       "       [   12.07,    38.25,  1012.67,    81.66],\n",
       "       [   26.91,    74.99,  1005.64,    78.98],\n",
       "       ..., \n",
       "       [   24.32,    66.25,  1009.09,    91.89],\n",
       "       [   23.49,    42.8 ,  1013.96,    65.31],\n",
       "       [   21.76,    60.27,  1018.96,    85.06]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7176, 5)\n"
     ]
    }
   ],
   "source": [
    "print(data_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2392, 4)\n"
     ]
    }
   ],
   "source": [
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(data,Y,m):\n",
    "    cost=0\n",
    "    M=len(data)\n",
    "    for i in range(len(data)):\n",
    "        cost+=(1/M)*((data[i].dot(m))-Y[i])**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient(data,Y,learningRate,m):\n",
    "    M=len(data)\n",
    "    N=data.shape[1]\n",
    "    sum_=np.zeros((N,1)) \n",
    "    m=m-(-2/M)*learningRate*(data.T).dot(Y.reshape(7176,1)-data.dot(m))   \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(data,Y,learningRate,numIter):\n",
    "    N=data.shape[1]\n",
    "    m=np.zeros((N,1))\n",
    "    \n",
    "    for i in range(numIter):        \n",
    "        m=step_gradient(data,Y,learningRate,m) \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    #loading data\n",
    "    data_input = np.loadtxt('Datasets/gd_project2_train.csv',delimiter=',')\n",
    "    data_test = np.loadtxt('Datasets/gd_project2_test.csv',delimiter=',')\n",
    "    #checking the shape\n",
    "    print(data_input.shape)\n",
    "    print(data_test.shape)\n",
    "    # Spliting intp inputs and outputs for the algorithm\n",
    "    X = data_input[:,0:4]\n",
    "    Y = data_input[:,4]\n",
    "    data_train = np.c_[np.ones(len(X)),X ]\n",
    "    data_test = np.c_[np.ones(len(data_test)),data_test ] \n",
    "        \n",
    "    \n",
    "     #adding some extra features\n",
    "    for i in range(1,X.shape[1]+1):\n",
    "        for j in range(i,X.shape[1]+1):\n",
    "            col = data_train[:,i]*data_train[:,j]\n",
    "            col_test = data_test[:,i]*data_test[:,j]\n",
    "\n",
    "            #print myData.shape,col.shape\n",
    "            data_train = np.append(data_train,col.reshape(7176,1),axis=1)\n",
    "            data_test = np.append(data_test,col_test.reshape(2392,1),axis=1)\n",
    "\n",
    "            \n",
    "    #normalize features code\n",
    "    for i in range(1,data_train.shape[1]):\n",
    "        Avg = data_train[:,i].mean()\n",
    "        deviation = data_train[:,i].std()\n",
    "        data_train[:,i] = (data_train[:,i]-Avg)/deviation\n",
    "    #end of normalization\n",
    "    \n",
    "    #normalize features code\n",
    "    for i in range(1,data_test.shape[1]):\n",
    "        Avg = data_test[:,i].mean()\n",
    "        deviation = data_test[:,i].std()\n",
    "        data_test[:,i] = (data_test[:,i]-Avg)/deviation\n",
    "    #end of normalization\n",
    "\n",
    "            \n",
    "    #normalize features code\n",
    "    for i in range(1,data_train.shape[1]):\n",
    "        Avg = data_train[:,i].mean()\n",
    "        deviation = data_train[:,i].std()\n",
    "        data_train[:,i] = (data_train[:,i]-Avg)/deviation\n",
    "    #end of normalization\n",
    "    \n",
    "    #normalize features code\n",
    "    for i in range(1,data_test.shape[1]):\n",
    "        Avg = data_test[:,i].mean()\n",
    "        deviation = data_test[:,i].std()\n",
    "        data_test[:,i] = (data_test[:,i]-Avg)/deviation\n",
    "    #end of normalization\n",
    "\n",
    "\n",
    "    learningRate=0.00004\n",
    "    numIterations=1000000\n",
    "    m=gradient_descent(data_train,Y,learningRate,numIterations)\n",
    "    print(m)\n",
    "    \n",
    "    y_predicted=data_test.dot(m)\n",
    "    print(y_predicted.shape)\n",
    "    np.savetxt('output_GasPower.csv',y_predicted,fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7176, 5)\n",
      "(2392, 4)\n",
      "[[  4.54431293e+02]\n",
      " [ -6.30091666e+00]\n",
      " [ -2.06025048e+00]\n",
      " [  3.39919200e-01]\n",
      " [  1.58781666e+00]\n",
      " [  2.38377523e+00]\n",
      " [  1.21487785e+00]\n",
      " [ -6.29958259e+00]\n",
      " [ -4.15423616e+00]\n",
      " [  9.05197842e-01]\n",
      " [ -2.06564455e+00]\n",
      " [ -5.46102482e-01]\n",
      " [  2.22006522e-01]\n",
      " [  1.45568258e+00]\n",
      " [ -1.96590298e+00]]\n",
      "(2392, 1)\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
